{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis of Last Jedi Audience Reviews\n",
    "This notebook assumes you have already scraped audience reviews from Rotten Tomatoes. This notebook will analyze frequence of ngrams and try some text classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>840073561</td>\n",
       "      <td>['Jeffrey O']</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[\"At least it was sort of original? Other than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>977007867</td>\n",
       "      <td>['Claire R']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[\"The acting was great but the story writing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976967449</td>\n",
       "      <td>['Caleb D']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>['Would not recommend for so many reasons. Thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>977007880</td>\n",
       "      <td>['James F']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>['Horrible. Just watch any of the Youtube stuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>977007877</td>\n",
       "      <td>['Michael C']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['Really good movie better than Force Awakens ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid       username  rating  \\\n",
       "0  840073561  ['Jeffrey O']     2.5   \n",
       "1  977007867   ['Claire R']     0.5   \n",
       "2  976967449    ['Caleb D']     0.5   \n",
       "3  977007880    ['James F']     0.5   \n",
       "4  977007877  ['Michael C']     4.0   \n",
       "\n",
       "                                                text  \n",
       "0  [\"At least it was sort of original? Other than...  \n",
       "1  [\"The acting was great but the story writing w...  \n",
       "2  ['Would not recommend for so many reasons. Thi...  \n",
       "3  ['Horrible. Just watch any of the Youtube stuf...  \n",
       "4  ['Really good movie better than Force Awakens ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the reviews file\n",
    "os.chdir(r\"O:\\PDES\\PRISM\\Sullivan\\Personal Projects\")\n",
    "reviewtbl = pd.read_csv(\"RT_Last_Jedi_2017-12-28.txt\", sep=\"\\t\")\n",
    "\n",
    "#check - well at least the export/import fixes some of my string issues\n",
    "reviewtbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup stop words\n",
    "from nltk.corpus import stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "mywords = set([\"star\", \"wars\", \"movie\", \"film\"])\n",
    "#add custom words\n",
    "stop_words = set(stopwords.words('english')) | mywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saw',\n",
       " 'weekend',\n",
       " 'afterwards',\n",
       " 'really',\n",
       " 'think',\n",
       " 'lot',\n",
       " 'mixed',\n",
       " 'feeling',\n",
       " 'lot',\n",
       " 'thinking',\n",
       " 'determined',\n",
       " 'really',\n",
       " 'liked',\n",
       " 'wa',\n",
       " 'different',\n",
       " 'made',\n",
       " 'lot',\n",
       " 'bold',\n",
       " 'choice',\n",
       " 'opinion',\n",
       " 'give',\n",
       " 'credit',\n",
       " 'lot',\n",
       " 'thing',\n",
       " 'unexpected',\n",
       " 'really',\n",
       " 'thought',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'really',\n",
       " 'good',\n",
       " 'idea',\n",
       " 'acting',\n",
       " 'good',\n",
       " 'especially',\n",
       " 'mark',\n",
       " 'hamill',\n",
       " 'carrie',\n",
       " 'fisher',\n",
       " 'comedy',\n",
       " 'usually',\n",
       " 'good',\n",
       " 'visuals',\n",
       " 'course',\n",
       " 'good',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'stuff',\n",
       " 'rey',\n",
       " 'luke',\n",
       " 'part',\n",
       " 'dragged',\n",
       " 'wa',\n",
       " 'subplot',\n",
       " 'finn',\n",
       " 'rose',\n",
       " 'rose',\n",
       " 'character',\n",
       " 'care',\n",
       " 'much',\n",
       " 'even',\n",
       " 'though',\n",
       " 'wa',\n",
       " 'low',\n",
       " 'point',\n",
       " 'wa',\n",
       " 'terrible',\n",
       " 'overall',\n",
       " 'wa',\n",
       " 'great',\n",
       " 'feel',\n",
       " 'fresh',\n",
       " 'really',\n",
       " 'think',\n",
       " 'appreciate',\n",
       " 'would',\n",
       " 'say',\n",
       " 'like',\n",
       " 'one',\n",
       " 'bit',\n",
       " 'force',\n",
       " 'awakens']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#clean and stem the review text\n",
    "def txtclean(mytxt, stop_words, lmtzr):\n",
    "    #convert to list of words\n",
    "    tokens = nltk.word_tokenize(mytxt)\n",
    "    \n",
    "    #keep only alphanumreic\n",
    "    words = [x for x in [re.sub(\"\\W\",\"\",x) for x in tokens] if x.isalpha()]\n",
    "    \n",
    "    #lemmatize  - odd treatment of 'was'\n",
    "    std_words = [lmtzr.lemmatize(t) for t in words]\n",
    "    \n",
    "    #remove standard stop words (convert to lower) and return\n",
    "    return [w for w in [x.lower() for x in std_words] if not w in stop_words]\n",
    "\n",
    "#example\n",
    "txtclean(reviewtbl[\"text\"][14], stop_words, WordNetLemmatizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'saw',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'on',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'and',\n",
       " 'afterwards',\n",
       " 'I',\n",
       " 'really',\n",
       " 'had',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'it',\n",
       " 'because',\n",
       " 'I',\n",
       " 'had',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'mixed',\n",
       " 'feeling',\n",
       " 'After',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'thinking',\n",
       " 'I',\n",
       " 'have',\n",
       " 'determined',\n",
       " 'that',\n",
       " 'I',\n",
       " 'really',\n",
       " 'liked',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'It',\n",
       " 'wa',\n",
       " 'very',\n",
       " 'different',\n",
       " 'from',\n",
       " 'the',\n",
       " 'other',\n",
       " 'Star',\n",
       " 'Wars',\n",
       " 'film',\n",
       " 'and',\n",
       " 'made',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'bold',\n",
       " 'choice',\n",
       " 'in',\n",
       " 'my',\n",
       " 'opinion',\n",
       " 'which',\n",
       " 'I',\n",
       " 'have',\n",
       " 'to',\n",
       " 'give',\n",
       " 'credit',\n",
       " 'for',\n",
       " 'There',\n",
       " 'were',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'were',\n",
       " 'unexpected',\n",
       " 'that',\n",
       " 'when',\n",
       " 'I',\n",
       " 'really',\n",
       " 'thought',\n",
       " 'about',\n",
       " 'it',\n",
       " 'it',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'they',\n",
       " 'were',\n",
       " 'really',\n",
       " 'good',\n",
       " 'idea',\n",
       " 'All',\n",
       " 'the',\n",
       " 'acting',\n",
       " 'in',\n",
       " 'this',\n",
       " 'film',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'especially',\n",
       " 'from',\n",
       " 'Mark',\n",
       " 'Hamill',\n",
       " 'and',\n",
       " 'Carrie',\n",
       " 'Fisher',\n",
       " 'The',\n",
       " 'comedy',\n",
       " 'is',\n",
       " 'usually',\n",
       " 'good',\n",
       " 'and',\n",
       " 'the',\n",
       " 'visuals',\n",
       " 'are',\n",
       " 'of',\n",
       " 'course',\n",
       " 'very',\n",
       " 'good',\n",
       " 'I',\n",
       " 'really',\n",
       " 'enjoyed',\n",
       " 'the',\n",
       " 'stuff',\n",
       " 'with',\n",
       " 'Rey',\n",
       " 'and',\n",
       " 'Luke',\n",
       " 'The',\n",
       " 'only',\n",
       " 'part',\n",
       " 'for',\n",
       " 'me',\n",
       " 'that',\n",
       " 'dragged',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'wa',\n",
       " 'the',\n",
       " 'subplot',\n",
       " 'with',\n",
       " 'Finn',\n",
       " 'and',\n",
       " 'Rose',\n",
       " 'The',\n",
       " 'Rose',\n",
       " 'character',\n",
       " 'I',\n",
       " 'did',\n",
       " 'not',\n",
       " 'care',\n",
       " 'for',\n",
       " 'too',\n",
       " 'much',\n",
       " 'Even',\n",
       " 'though',\n",
       " 'that',\n",
       " 'wa',\n",
       " 'the',\n",
       " 'low',\n",
       " 'point',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'not',\n",
       " 'terrible',\n",
       " 'Overall',\n",
       " 'it',\n",
       " 'wa',\n",
       " 'a',\n",
       " 'a',\n",
       " 'great',\n",
       " 'Star',\n",
       " 'Wars',\n",
       " 'film',\n",
       " 'that',\n",
       " 'feel',\n",
       " 'fresh',\n",
       " 'and',\n",
       " 'you',\n",
       " 'really',\n",
       " 'have',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'to',\n",
       " 'appreciate',\n",
       " 'it',\n",
       " 'I',\n",
       " 'would',\n",
       " 'say',\n",
       " 'that',\n",
       " 'I',\n",
       " 'like',\n",
       " 'this',\n",
       " 'one',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'more',\n",
       " 'then',\n",
       " 'The',\n",
       " 'Force',\n",
       " 'Awakens']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#[x.lower() for x in baz]\n",
    "lmtzr = WordNetLemmatizer()\n",
    "[lmtzr.lemmatize(t) for t in baz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>clean text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>840073561</td>\n",
       "      <td>['Jeffrey O']</td>\n",
       "      <td>2.5</td>\n",
       "      <td>[\"At least it was sort of original? Other than...</td>\n",
       "      <td>least wa sort original story hoaky dialogue ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>977007867</td>\n",
       "      <td>['Claire R']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[\"The acting was great but the story writing w...</td>\n",
       "      <td>acting wa great story writing wa aweful know q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>976967449</td>\n",
       "      <td>['Caleb D']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>['Would not recommend for so many reasons. Thi...</td>\n",
       "      <td>would recommend many reason wa poorly written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>977007880</td>\n",
       "      <td>['James F']</td>\n",
       "      <td>0.5</td>\n",
       "      <td>['Horrible. Just watch any of the Youtube stuf...</td>\n",
       "      <td>horrible watch youtube stuff skewering detail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>977007877</td>\n",
       "      <td>['Michael C']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['Really good movie better than Force Awakens ...</td>\n",
       "      <td>really good better force awakens equal return ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userid       username  rating  \\\n",
       "0  840073561  ['Jeffrey O']     2.5   \n",
       "1  977007867   ['Claire R']     0.5   \n",
       "2  976967449    ['Caleb D']     0.5   \n",
       "3  977007880    ['James F']     0.5   \n",
       "4  977007877  ['Michael C']     4.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  [\"At least it was sort of original? Other than...   \n",
       "1  [\"The acting was great but the story writing w...   \n",
       "2  ['Would not recommend for so many reasons. Thi...   \n",
       "3  ['Horrible. Just watch any of the Youtube stuf...   \n",
       "4  ['Really good movie better than Force Awakens ...   \n",
       "\n",
       "                                          clean text  \n",
       "0  least wa sort original story hoaky dialogue ab...  \n",
       "1  acting wa great story writing wa aweful know q...  \n",
       "2  would recommend many reason wa poorly written ...  \n",
       "3      horrible watch youtube stuff skewering detail  \n",
       "4  really good better force awakens equal return ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put cleaned results back into a long string for use by sklearn\n",
    "testwrds = txtclean(reviewtbl[\"text\"][14], stop_words, WordNetLemmatizer())\n",
    "\" \".join(testwrds)\n",
    "\n",
    "reviewtbl['clean text'] = [\" \".join(txtclean(x, stop_words, WordNetLemmatizer())) for x in reviewtbl['text']]\n",
    "reviewtbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall 1\n",
      "bit 1\n",
      "rey 1\n",
      "weekend 1\n",
      "rose 2\n",
      "great 1\n",
      "fresh 1\n",
      "course 1\n",
      "different 1\n",
      "idea 1\n",
      "even 1\n",
      "appreciate 1\n",
      "usually 1\n",
      "mixed 1\n",
      "low 1\n",
      "think 2\n",
      "point 1\n",
      "awakens 1\n",
      "carrie 1\n",
      "star 2\n",
      "subplot 1\n",
      "mark 1\n",
      "bold 1\n",
      "though 1\n",
      "opinion 1\n",
      "felt 1\n",
      "character 1\n",
      "thinking 1\n",
      "stuff 1\n",
      "feel 1\n",
      "luke 1\n",
      "would 1\n",
      "much 1\n",
      "terrible 1\n",
      "one 1\n",
      "determined 1\n",
      "movie 3\n",
      "made 1\n",
      "good 4\n",
      "film 3\n",
      "give 1\n",
      "feeling 1\n",
      "fisher 1\n",
      "dragged 1\n",
      "afterwards 1\n",
      "like 2\n",
      "wa 5\n",
      "hamill 1\n",
      "part 1\n",
      "credit 1\n",
      "finn 1\n",
      "say 1\n",
      "saw 1\n",
      "choice 1\n",
      "thought 1\n",
      "especially 1\n",
      "care 1\n",
      "really 6\n",
      "thing 1\n",
      "unexpected 1\n",
      "force 1\n",
      "lot 4\n",
      "wars 2\n",
      "comedy 1\n",
      "acting 1\n",
      "liked 1\n",
      "visuals 1\n",
      "enjoyed 1\n"
     ]
    }
   ],
   "source": [
    "#scratch - testing nltk ngram approach\n",
    "testwrds = txtclean(reviewtbl[\"text\"][14], stop_words, WordNetLemmatizer())\n",
    "bgs = nltk.bigrams(testwrds)\n",
    "\n",
    "fdist = nltk.FreqDist(testwrds)\n",
    "for k,v in fdist.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method from stackoveflow\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "word_vectorizer = CountVectorizer(ngram_range=(1,3), analyzer='word')\n",
    "sparse_matrix = word_vectorizer.fit_transform(reviewtbl[reviewtbl[\"rating\"]<3.5][\"clean text\"])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "allngrams = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>last jedi</th>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force awakens</th>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rian johnson</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luke skywalker</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot hole</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first order</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original trilogy</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character development</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel like</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kylo ren</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doe nt</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa nt</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mark hamill</th>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jj abrams</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst ever</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rogue one</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make sense</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa good</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new character</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story line</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jar jar</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca nt</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt like</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awakens wa</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>luke character</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finn rose</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa bad</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wo nt</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like wa</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many plot</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell supposed</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell shame</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell kind</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hell achieve</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>held highest</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>held check</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heir empire</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height terribly</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heck wa</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help doe</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help doesnt</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help either</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heritage like</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hero cutandrun</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hero creating</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hero came</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hero achieved</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hermit try</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hermit stuck</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hermit full</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heralded age</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help feeling</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helped modernize</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helped along</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help unwatch</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help save</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help princess</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help note</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>help jj</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zooming screen</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       frequency  n\n",
       "last jedi                    139  2\n",
       "force awakens                109  2\n",
       "rian johnson                 102  2\n",
       "luke skywalker                97  2\n",
       "plot hole                     91  2\n",
       "first order                   46  2\n",
       "original trilogy              44  2\n",
       "character development         43  2\n",
       "feel like                     41  2\n",
       "kylo ren                      41  2\n",
       "doe nt                        35  2\n",
       "wa nt                         33  2\n",
       "mark hamill                   31  2\n",
       "jj abrams                     30  2\n",
       "worst ever                    28  2\n",
       "rogue one                     28  2\n",
       "make sense                    28  2\n",
       "wa good                       25  2\n",
       "new character                 25  2\n",
       "story line                    21  2\n",
       "jar jar                       21  2\n",
       "ca nt                         21  2\n",
       "felt like                     21  2\n",
       "awakens wa                    21  2\n",
       "luke character                20  2\n",
       "finn rose                     20  2\n",
       "wa bad                        19  2\n",
       "wo nt                         19  2\n",
       "like wa                       19  2\n",
       "many plot                     19  2\n",
       "...                          ... ..\n",
       "hell supposed                  1  2\n",
       "hell shame                     1  2\n",
       "hell kind                      1  2\n",
       "hell achieve                   1  2\n",
       "held highest                   1  2\n",
       "held check                     1  2\n",
       "heir empire                    1  2\n",
       "height terribly                1  2\n",
       "heck wa                        1  2\n",
       "help doe                       1  2\n",
       "help doesnt                    1  2\n",
       "help either                    1  2\n",
       "heritage like                  1  2\n",
       "hero cutandrun                 1  2\n",
       "hero creating                  1  2\n",
       "hero came                      1  2\n",
       "hero achieved                  1  2\n",
       "hermit try                     1  2\n",
       "hermit stuck                   1  2\n",
       "hermit full                    1  2\n",
       "heralded age                   1  2\n",
       "help feeling                   1  2\n",
       "helped modernize               1  2\n",
       "helped along                   1  2\n",
       "help unwatch                   1  2\n",
       "help save                      1  2\n",
       "help princess                  1  2\n",
       "help note                      1  2\n",
       "help jj                        1  2\n",
       "zooming screen                 1  2\n",
       "\n",
       "[24972 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allngrams['n'] = [len(x.split()) for x in allngrams.index]\n",
    "allngrams[allngrams['n']==2].sort_values('frequency', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
